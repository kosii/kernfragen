\documentclass[11pt]{article}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{}


\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\sumn}[4]{\sum_{#1=#2}^{#3}{#4}}
\newcommand{\RR}[0]{\mathbb{R}}
\newcommand{\CC}[0]{\mathbb{C}}
\newcommand{\QQ}[0]{\mathbb{Q}}
\newcommand{\ZZ}[0]{\mathbb{Z}}
\newcommand{\NN}[0]{\mathbb{N}}
\newcommand{\KK}[0]{\mathbb{K}}
\newcommand{\smallo}[0]{{\scriptstyle \mathcal{O}}}

\setlength{\topmargin}{-.5in} \setlength{\textheight}{9.25in}
\setlength{\oddsidemargin}{0in} \setlength{\textwidth}{6.8in}


\begin{document}

\noindent{\bf Kernfragen - Differentiation\hfill Balázs Kossovics \hfill WS21-22 Analysis I.}


\medskip\hrule
\begin{enumerate}
    \item Wann heißt eine Funktion $f\colon \RR\to\RR$ in einem Punkt $x_0$ differenzierbar? Wie lässt sich die Ableitung geometisch interpretieren?
    
    \textbf{Answer:}
    If the $\lim_{x\to x_0}\frac{f(x_0 + h) - f(x_0)}{h}$ exists, then we call the function $f$ differentiable in the $x_0$ point. We call the value of $\lim_{x\to x_0}\frac{f(x_0 + h) - f(x_0)}{h}$ the derivative of the function $f$ in point $x_0$ and we denote it with $f^\prime(x_0)$. Whenever the derivative of a function exists, it's unique.

    The value of the $f^\prime(x_0)$ is the coefficient of $x$ in the best linear approximation of $f$ at point $x_0$, and it's the slope of the tangent line drawn to the function at the point $(x_0, f(x_0))$.

    \item  Gib Beispiele für Funtionen $f\colon \RR\to\RR$ an, die
    \begin{enumerate}
        \item stetig, aber in $x_0 = 0$ nicht differenzierbar;
        \item differenzierbar, aber nicht gleichmäßig stetig;
        \item differenzierbar, aber in $x_0 = 0$ nicht stetig differenzierbar sind
    \end{enumerate}

    \textbf{Answer:}

    \begin{enumerate}
        \item $f(x) = \abs{x}$
        \item $f(x) = x^2$
        \item $f(x) = \begin{cases}
            x^2 \sin{\frac{1}{x}}&x\neq0\\
            0&x=0
        \end{cases}$
    \end{enumerate}

    % Question 3
    \item Was bedeuten die Landau-Symbole $\smallo(h)$, $\mathcal{O}(h^2)$ und ${ \scriptstyle \mathcal{O}}(1)$? Wie lassen sich Stetigkeit und Differenzierbarkeit mit ihrer Hilfe ausdrücken?
    
    \textbf{Answer:}
    \begin{enumerate}
        \item $f(h) = \smallo(h) \Leftrightarrow \lim_{h\to0}\frac{f(h)}{h} = 0$
        \item $f(h) = \mathcal{O}(h^2) \Leftrightarrow \limsup_{h\to0}\abs{\frac{f(h)}{h^2}} < \infty$
        \item $f(h) = \smallo(1) \Leftrightarrow \lim_{h\to0} f(h) = 0$
    \end{enumerate}

    If there is a number $\alpha \in \RR$ such that $f(x_0+h) = f(x_0) + \alpha h + \smallo(h)$, then we say that the function $f$ is differentiable in the $x_0$ point.

    We say that $f$ is continuous in $x_0$ if $f(x_0 + h) = f(x_0) + \smallo(1)$

    % Question 4
    \item Für welche reellen $\alpha$ ist $\abs{x}^\alpha$ in $x = 0$ reell differenzierbar?
    
    \textbf{Answer:}
    \begin{enumerate}
        \item $\alpha = 0$: Besides the intuitive definition, it's reasonable to consider $\abs{0}^0 = \lim_{x\to0} x^0 = 1$ if we want the general exponentiation to be continuous as a function of its base. Since $\forall x \neq 0\colon \abs{x}^0 = 1$, $f$ is the constant $1$ function and thus it's differentiable everywhere, also in particular in $0$.
        \item $\alpha < 0$: $\lim_{x\to0} = \infty$ and thus $f$ is not continuous in $0$ and thus its derivative does not exists
        \item $0 < \alpha < 1$: $f(0) = 0$ and thus $\lim_{h\to0^-}\frac{f(h) - f(0)}{h} = \lim_{h\to0^-}\frac{\abs{h}^\alpha}{h} = -\infty \neq +\infty = \lim_{h\to0^+}\frac{f(h) - f(0)}{h}$, thus it's not differentiable
        \item $\alpha = 1\colon \lim_{h\to0^+}\frac{f(h) - f(0)}{h} = \lim_{h\to0^+}\operatorname{sgn}(h)\abs{h}^{\alpha-1} = 1 \neq -1 = \lim_{h\to0^-}\operatorname{sgn}(h)\abs{h}^{\alpha-1}$, thus it's not differentiable in $0$
        \item $\alpha > 0\colon \lim_{h\to0}\frac{f(h) - f(0)}{h} = \lim_{h\to0} \operatorname{sgn}(h)\abs{h}^{\alpha-1} = 0$ thus it's differentiable 
    \end{enumerate}

    % Question 5
    \item Wie lautet die Produktregel für Ableitungen? Warum gilt sie (Beweis)?
    
    \textbf{Answer:}

    Consider two functions $f$ and $g$ that are both differentiable in some $x_0$ point of their domain. Then the $f g$ function is also differentiable in $x_0$ and $(f g)^\prime(x_0) = f^\prime(x_0) g(x_0) + f(x_0) g^\prime(x_0)$
    
    \textit{Proof:}
    $$\begin{aligned}
        &\lim_{h\to0}\frac{f(x_0 + h)g(x_0 + h) - f(x_0)g(x_0)}{h} \\
        =&\lim_{h\to0}\frac{f(x_0 + h)g(x_0 + h) - f(x)g(x_0 + h) + f(x)g(x_0 + h)- f(x_0)g(x_0)}{h}\\
        =&\lim_{h\to0}\frac{(f(x_0 + h)- f(x))g(x_0 + h) + f(x)(g(x_0 + h)- g(x_0))}{h}
    \end{aligned}$$

    Since $g$ is continuous in $x_0$ and the $\lim_{h\to0}\frac{f(x_0 + h)- f(x)}{h}$ and $\lim_{h\to0}\frac{g(x_0 + h)- g(x)}{h}$ exist, thus the above limit also exists and 
    $$\begin{aligned}&= \lim_{h\to0}\frac{f(x_0 + h)- f(x)}{h} g(x_0 + h) + f(x)\frac{g(x_0 + h)- g(x)}{h} \\&=f^\prime(x_0) g(x_0) + f(x_0) g^\prime(x_0)\end{aligned}$$

    \item Wie lauten Quotienten- und Kettenregel für Ableitungen?
    
    \textbf{Answer:}

    \textit{Division:} Suppose that both $f$ and $g$ functions are differentiable in $x_0$ and furthermore suppose that $g(x_0) \neq 0$. Then the function $\frac{f}{g}$ is also differentiable in $x_0$ and $\left(\frac{f}{g}\right)^\prime(x_0) = \frac{f^\prime(x_0)g(x_0)-f(x_0)g^\prime(x_0)}{g^2(x_0)}$
    
    \textit{Chain rule:} Suppose that $g$ is differentiable in some $x_0$ point and $f$ is differentiable in $y_0 = f(x_0)$. Then $f \circ g$ is also differentiable in $x_0$ and $(f \circ g)^\prime(x_0) = f^\prime(g(x_0))g^\prime(x_0)$

    \item Was sind die Ableitungen folgender Funktionen nach $x$?
    
    \hspace*{\fill}
    $e^x \sin{x} \hfill \frac{\sin{x}}{\cos{x}}\hfill \exp(-x^2)\hfill \log{\frac{1+x}{1-x}}\hfill x^x$
    \hspace*{\fill}

    \textbf{Answer:}
    \begin{enumerate}
        \item $(e^x \sin{x})^\prime = e^x \sin{x} + e^x \cos{x}$ from the product rule because $\exp^\prime = \exp$ and $\sin^\prime = \cos$
        \item Suppose that $x \neq \frac{\pi}{2} + k\pi~(k \in \ZZ)$. Then $\frac{\sin{x}}{\cos{x}} = \frac{\cos^2{x} + \sin^2{x}}{\cos^2{x}} = \frac{1}{\cos^2{x}}$ from the rule of division
        \item $(\exp(-x^2))^\prime = -2x\exp(-x^2)$ from the chain rule
        \item For $x > 1\colon (\log\frac{1+x}{1-x})^\prime = \frac{1}{\frac{1+x}{1-x}} (\frac{1+x}{1-x})^\prime = \frac{1-x}{1+x} \frac{(1-x) + (1+x)}{(1-x)^2}=\frac{2}{1-x^2}$
        \item For $x > 0\colon (x^x)^\prime = (\exp(x \log{x}))^\prime = x^x (\log{x} + x\frac{1}{x}) = x^x (\log{x} + 1)$
    \end{enumerate}

    %Question 8
    \item Wann besitzt eine Funktion $f\colon \RR\to\RR$ eine differenzierbare Umkehrfunktion $f^{-1}$?
    
    \textbf{Answer:} Suppose that $f$ is continuous, injective and differentiable in some $x_0 \in \RR$ point with $f^\prime(x_0) \neq 0$. Then the inverse function  $f^{-1}\colon J \to \RR~(J = f(\RR))$ exists, also injective and continuous, and furthermore differentiable in $y_0 = f(x_0)$ with $(f^{-1})^\prime(y_0) = \frac{1}{f^\prime(f^{-1}(y_0))} = \frac{1}{f^\prime(x_0)}$

    \item Wie lautet der Mittelwertsatz (der Differentialrechnung)? Wie lautet der Satz von
    Rolle?

    \textbf{Answer:}

    \textit{Mean Value Theorem:} Consider some continuous function $f\colon [a, b] \to \RR$ which is differentiable on $(a, b)$. Then $\exists c \in (a, b)\colon \frac{f(b) - f(a)}{b - a} = f^\prime(c)$

    \textit{Rolle:} Consider some continuous function $f\colon [a, b] \to \RR$ which is differentiable on $(a, b)$, and suppose that $f(a) = f(b)$. Then $\exists c\in(a, b)\colon f^\prime(c) = 0$

    % Question 10
    \item Warum gilt der Satz von Rolle (Beweisskizze)?
    
    \textbf{Answer:} Since $f$ is continuous on $[a, b]$, it'll take on its extrema $m = \min_{x \in [a, b]}{f(x)}$ and $M = \max_{x \in [a, b]}{f(x)}$. If $m = M$, then the function is constant, and thus $f^\prime(x) = 0~(\forall x\in(a, b))$. If $m \neq M$, then at least one of the place of extrema is an inner point of $[a, b]$. Without loss of generality, suppose that $m = f(c)$ for some $c \in (a, b)$ (otherwise consider $-f$). If $c$ is a minimum point, then it's also a local minima, and we know that for inner local minimum and maximum, if the function is differentiable at that point, then the derivative is $0$. Since we assumed $f$ to be differentiable on $(a, b)$, thus $f^\prime(c) = 0$.

    \item Wie lauten die Regeln von de l'Hôpital?
    
    \textbf{Answer:} Consider two functions $f, g$ that are differentiable on an open interval containing some $x_0$ point (except maybe at this point) and suppose that $\lim_{x \to x_0}f(x) = \lim_{x \to x_0} g(x) = 0$ and that $\lim_{x \to x_0}\frac{f^\prime(x)}{g^\prime(x)}$ exists. Then $\lim_{x \to x_0}\frac{f(x)}{g^(x)}$ also exists and $\lim_{x \to x_0}\frac{f(x)}{g^(x)} = \lim_{x \to x_0}\frac{f^\prime(x)}{g^\prime(x)}$

    \textit{Variants}
    \begin{itemize}
        \item If $\lim_{x \to x_0}f(x) = \lim_{x \to x_0} g(x) = \pm \infty$ and $\lim_{x \to x_0}\frac{f^\prime(x)}{g^\prime(x)}$ exists (and finite!), then $\lim_{x \to x_0}\frac{f(x)}{g^(x)}$ also exists and $\lim_{x \to x_0}\frac{f(x)}{g^(x)} = \lim_{x \to x_0}\frac{f^\prime(x)}{g^\prime(x)}$
        \item Instead of a fix $x_0$ point we can consider the limits in $\pm \infty$
        \item We can use the theorem repeatedly as long as we have $0/0$ or $\pm\frac{\infty}{\infty}$ and the functions are sufficiently many times differentiable
    \end{itemize}

    % Question 12
    \item Welche Werte haben die stetigen Fortsetzungen folgender Funktionen in $x = 0$?
    
    \hspace*{\fill}
    $f(x) = \frac{\sin{x}}{x} \hfill g(x) = \frac{\cos{x} - 1}{x^2} \hfill h(x) = \frac{\log(1+x)}{x} \hfill r(x) = \frac{x}{e^x -1}$
    \hspace*{\fill}

    \textbf{Answer:}

    \begin{enumerate}
        \item \label{itm:first} yes, with $f(x) = 0$ because $\lim_{x\to0}\frac{\sin{x}}{x} = \lim_{x\to0} \frac{\cos{x}}{1} = 1$ (from l'Hôpital)
        \item yes, with $g(x) = -\frac{1}{2}$ because $\lim_{x \to 0}\frac{\cos{x} - 1}{x^2} = \lim_{x \to 0}\frac{-\sin{x}}{2x} = -\frac{1}{2}$ (from l'Hôpital and \ref{itm:first})
        \item yes, with $h(x) = 1$ because $\lim_{x \to 0}\frac{\log(1+x)}{x} = \lim_{x \to 0}\frac{\frac{1}{1+x}}{1} = 1$ (from l'Hôpital)
        \item yes, with $r(x) = 1$ because $\lim_{x \to 0}\frac{x}{e^x -1} = \lim_{x \to 0}\frac{1}{e^x} = 1$ (from l'Hôpital)
    \end{enumerate}

    % Question 13
    \item Berechne
    $$\lim_{x \to +\infty}\frac{e^x - e^{-x}}{e^x + e^{-x}}$$

    \textbf{Answer:}
    $\lim_{x \to +\infty}\frac{e^x - e^{-x}}{e^x + e^{-x}} = \lim_{x \to +\infty}\frac{e^x(1 - e^{-2x})}{e^x(1 + e^{-2x})} = \lim_{x \to +\infty}\frac{1 - e^{-2x}}{1 + e^{-2x}} = 1$
    % Question 14
    \item Wie lauten die Ungleichungen von Young und Hölder?
    
    \textbf{Answer:}

    \textit{Young's inequality:} Consider $x, y \ge 0$ and $p, q > 1$ with $\frac{1}{p} + \frac{1}{q} = 1$. It holds that $x^{1/p} + y^{1/q} \le \frac{x}{p} + \frac{y}{q}$.

    \textit{Hölder's inequality:} For $x, y \in \CC^n$ and $p, q > 1$ with $\frac{1}{p} + \frac{1}{q} = 1$ it holds that $\sumn{k}{1}{n}{\abs{x_k} \abs{y_k}} \le \norm{x}_p \norm{y}_q$ where $\norm{x}_p = \left(\sumn{k}{1}{n}{\abs{x_k}^p}\right)^{1/p}$ (that is: the $p$-norm ($1 \le p \le \infty$))

    
    % Question 15
    \item Skizziere die Funktionen $\sin{x}$ und $\cos{x}$, beschreibe ihre Nullstellen, Ableitungen, Monotonie, Konvexität und Konkavität, und erläutere unsere Definition von $\pi$.

    \textbf{Answer:} \textit{(not relevant for the first exam)}
    \begin{itemize}
        \item $\sin(x) = 0 \Leftrightarrow x = k\pi~(k \in \ZZ)$
        \item $\cos(x) = 0 \Leftrightarrow x = \frac{\pi}{2} + k\pi~(k \in \ZZ)$
        \item $\sin^\prime = \cos, \cos^\prime = -\sin$
    \end{itemize}
    


    \item Sei $f\colon \RR\to\RR$ eine zweimal differenzierbare Funktion. Welche (notwendige) Bedingung ist erfüllt, wenn $f$ an der Stelle $x_0$ ein lokales Maximum besitzt? Unter welcher (hinreichenden) Bedingung besitzt $f$ an der Stelle $x_0$ ein lokales Maximum?
    
    \textbf{Answer:} (\textit{these conditions are related to strict local maxima})

    Necessary condition: $f^\prime(x_0) = 0$

    Sufficient condition: $f^\prime(x_0) = 0$ and $f^{\prime\prime}(x_0) < 0$

    % Question 17
    \item Wann heißt eine Funktion $f\colon (a, b)\to\RR$ konvex? Wann heißt sie strikt konvex?
    
    \textbf{Answer:} $f$ is convex if $\forall x, y \in (a, b)$ such that $x < y, \forall t \in (0, 1)\colon f(t y + (1-t) x) \le tf(y) + (t-1)f(x)$. For strictly convex this holds with $<$ instead of $\le$.
    \item Die Funktion $f\colon (a, b)\to\RR$ sei zweimal diferenzierbar. Wie lassen sich Konvexität
    und strikte Konvexität durch Bedingungen an die zweite Ableitung ausdrücken?

    \textbf{Answer:} 
    \begin{enumerate}
        \item $f$ is convex if and only if $f^{\prime\prime} \ge 0$
        \item if $f^{\prime\prime} > 0$ then $f$ is strictly convex (it doesn't hold in the other direction: for example $x^4$ is strictly convex, but $(x^4)^{\prime\prime} = 12x^2 = 0$ for $x=0)$
    \end{enumerate}

    \item Wieviele Minima bzw. Maxima kann eine strikt konvexe Funktion $f\colon [a,b]\to\RR$ haben? (Gib alle möglichen Zahlen an.)
    
    \textbf{Answer:} A convex function is also continuous (see sheet 9. problem 34.). A continuous function on a bounded and closed interval takes on its extremal values. Suppose that $m = \min_{x\in[a,b]} f(x) = f(p)$ and $M = \max_{x\in[a,b]} f(x)$ (for some corresponding $p \in [a, b]$ value). $m \neq M$, otherwise the function would be constant, and thus it would not be strictly convex.

    Now suppose that the function has two local minima with $m_1 = f(p_1)$ and $m_2 = f(p_2)$. If a function is strictly convex, then it's nowhere constant, and thus if $m_1$ and $m_2$ are local minima, then they are also strict local minima and thus $\exists q$ between $p_1$ and $p_2$ such that $f(q) > \max(m_1, m_2)$. But then $f(q) > f((1-t)p_1 + t p_2)~(\forall t\in(0, 1))$ and this would contradict the strict convexity criteria. Consequently the function cannot have more than one local minimum, and since a global minimum is also a local minimum, they are necessarily the same.

    Since the function is nowhere constant, and cannot have other local minimum than the global minimum, it must be strictly monotone descreasing on $[a, p]$ and strictly monotone increasing on $[p, b]$. If $a \neq p$ then $f$ has a local maximum at $a$, and if $p \neq b$ then $f$ has a local maximum at $b$. If $f(a) = f(b)$ then they are both global maxima, otherwise the largest of them is the global maximum of $f$ on $[a, b]$.

    Thus there is exactly one local minimum and it corresponds to the global minimum. If the global minimum is not at one of the endpoints, then the function will have two local maxima at the endpoints of the interval. If they are the same, then they are both global maxima, otherwise the largest of them will be the global maximum. If the global minimum is at one of the endpoints, then the global maxima will be at the other endpoint.

    \item Wo sind (reelle) Potenzreihen differenzierbar? Wie lautet die Ableitung?
    
    \textbf{Answer:} A real power series $p(x) = \sumn{n}{0}{\infty}{a_n x^n}$ with convergence radius $\rho \in [0, \infty)$ is differentiable infinitely many times for any $\abs{x} < \rho$, and $p^\prime(x) = \sumn{n}{1}{\infty}{n a_n x^{n-1}} = \sumn{n}{0}{\infty}{(n+1)a_{n+1}x^n}$. We can define the $n^{\text{th}}~(n > 1)$ derivative recursively as $p^{(n)}(x) = (p^{(n-1)}(x))^\prime$ and with induction we get $p^{(n)}(x) = \sumn{k}{0}{\infty}{\frac{(k+n)!}{k!}a_{k+n}x^k}$


    \item Wie ist der Raum $\mathcal{BC}^1(\RR,\RR)$ definiert? Was bedeutet seine Vollständigkeit für die Vertauschbarkeit von Differentiation und Grenzwertbildung einer Funktionenfolge $f_n\colon \RR\to\RR$?
    
    \textbf{Answer} $\mathcal{BC}^1(\RR,\RR)$ is the vectorspace of continuously differentiable, bounded and continuous functions defined on $\RR$ with bounded derivative. $\mathcal{BC}^1(\RR,\RR)$ is a Banach-space (that is: normed and complete) with the $\norm{f}_{C^1} = \norm{f}_{C^0} + \norm{f^\prime}_{C^0}~(f \in \mathcal{BC}^1(\RR,\RR))$ norm (with $\norm{.}_{C^0}$ being the supremum-norm with which $\mathcal{BC}(\RR,\RR)$ is complete). 

    Since $\mathcal{BC}^1(\RR,\RR)$ with the norm $\norm{.}_{C^1}$ is complete, any Cauchy sequence $(f_n) \in \mathcal{BC}^1(\RR,\RR)$ is also convergent (under the norm), thus $\exists f \in \mathcal{BC}^1(\RR,\RR)$ such that $\lim_{n\to\infty}\norm{f_n - f}_{C^1} = 0$, or equivalently: $\norm{f_n - f}_{C^0} \to 0 \text{ and } \norm{f^\prime_n - f^\prime}_{C^0} \to 0~(n\to\infty)$. If we consider the convergence under the norm this also means that $(\lim_{n\to\infty}f_n)^\prime = f^\prime = \lim_{n\to\infty}f^\prime_n$, or: the derivative of the limit is the limit of the derivatives, that is: for any convergent $(f_n) \in \mathcal{BC}^1(\RR,\RR)$ the order of differentiation and taking the limit can be exchanged with regards to the $\norm{.}_{C^1}$.

    \item Wie lautet das $n$-te Taylor-Polynom? Wie kann das Restglied ausgedrückt werden?
    
    \textbf{Answer:} \textit{(not relevant for the first exam)}
    \item Wann (und wo) wird eine reelle Funktion durch ihre Taylor-Reihe dargestellt? Gib ein Beispiel und ein Gegenbeispiel.
    
    \textbf{Answer:} \textit{(not relevant for the first exam)}
    \item Wie lauten die Taylor-Reihen folgender Funktionen in $x_0 = 0$?
    \begin{center}
        $e^x$, $\sin{x}$, $\arctan{x}$, $(1+x)^\alpha$, $\log(1+x)$
    \end{center}

    \textbf{Answer:} \textit{(not relevant for the first exam)}
\end{enumerate}

\end{document} 
